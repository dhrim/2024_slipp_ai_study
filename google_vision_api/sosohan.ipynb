{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소소한 귀찮음\n",
    "- 첫번째 귀찮은 문제, anki의 데이터를 만들어서 해당 데이터형태 .apkg를 만들수 있는가?\n",
    "- 두번째 귀찮은 문제, 스캐너를 통한 pdf OCR적용이 엉망진창이다. (구글문서를 이용하더라도 결과엉망)\n",
    "- 세번째 귀찮은 문제, 각각 만들어서 파이썬으로 정답가지고 가고? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 첫번째 의문 질문해보기\n",
    "Anki 카드를 만들고 .apkg 파일로 내보내기 위해서는 Anki의 genanki 라이브러리를 사용할 수 있습니다. 위의 질문들과 제공된 정답을 매칭하여 Anki 카드를 생성하는 Python 프로그램을 작성하겠습니다.\n",
    "\n",
    "먼저, 질문과 정답을 매핑하고, 그 후에 genanki 패키지를 사용하여 Anki 카드 덱을 만들고 .apkg 파일을 생성하는 코드를 작성해야 합니다.\n",
    "\n",
    "다음 단계를 진행하겠습니다:\n",
    "\n",
    "genanki 패키지를 사용하기 위한 준비 작업\n",
    "질문과 정답을 매핑하여 Anki 노트를 만듭니다.\n",
    "Anki 덱을 생성하고 노트를 추가합니다.\n",
    ".apkg 파일을 생성합니다.\n",
    "아래는 해당 작업을 수행하는 Python 코드입니다. 이 코드를 실행하려면 로컬 환경에서 genanki 패키지가 설치되어 있어야 합니다. 현재 환경에서는 genanki를 설치할 수 없으므로, 이 코드를 복사하여 로컬 환경에서 실행하셔야 합니다.\n",
    "(아 맞다. 라이브러리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: genanki in ./.venv/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: cached-property in ./.venv/lib/python3.12/site-packages (from genanki) (1.5.2)\n",
      "Requirement already satisfied: frozendict in ./.venv/lib/python3.12/site-packages (from genanki) (2.4.0)\n",
      "Requirement already satisfied: chevron in ./.venv/lib/python3.12/site-packages (from genanki) (0.14.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from genanki) (6.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install genanki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anki 패키지 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import genanki\n",
    "\n",
    "# 질문과 정답을 리스트로 정의\n",
    "questions_answers = [\n",
    "    (\"다음 중 다른 데이터와 연결하여 분석하는 맵리듀스 패턴으로 올바른 것은?\", \"① 조인 패턴\"),\n",
    "    (\"다음 중 네트워크상에서 여러 호스트 컴퓨터의 공유된 데이터에 접근하는 올바른 방식은?\", \"① 분산 파일 시스템\"),\n",
    "    (\"다음 중 공공데이터와 같은 외부 데이터를 사용할 때의 장점으로 올바른 것은?\", \"① 비용이 상대적으로 낮다.\"),\n",
    "    (\"다음 중 데이터 정제에 대한 설명으로 옳지 않은 것은?\", \"④ 결측치 처리\"),\n",
    "    (\"다음 중 빅데이터 시대의 위험 요인으로 옳지 않은 것은?\", \"③ 인간-인간 상호작용 위기\"),\n",
    "]\n",
    "\n",
    "# genanki 덱 ID와 덱 이름 정의\n",
    "my_deck = genanki.Deck(\n",
    "    123456789,\n",
    "    '데이터 분석 기초 덱'\n",
    ")\n",
    "\n",
    "# genanki 모델(카드 형식) 정의\n",
    "my_model = genanki.Model(\n",
    "    123456789,\n",
    "    '기본 모델',\n",
    "    fields=[\n",
    "        {'name': 'Question'},\n",
    "        {'name': 'Answer'},\n",
    "    ],\n",
    "    templates=[\n",
    "        {\n",
    "            'name': 'Card 1',\n",
    "            'qfmt': '{{Question}}',\n",
    "            'afmt': '{{FrontSide}}<hr id=\"answer\">{{Answer}}',\n",
    "        },\n",
    "    ])\n",
    "\n",
    "# 질문과 정답을 Anki 노트로 변환하고 덱에 추가\n",
    "for qa in questions_answers:\n",
    "    note = genanki.Note(\n",
    "        model=my_model,\n",
    "        fields=[qa[0], qa[1]]\n",
    "    )\n",
    "    my_deck.add_note(note)\n",
    "\n",
    "# .apkg 파일 생성\n",
    "genanki.Package(my_deck).write_to_file('data_analysis_basic_deck.apkg')\n",
    "\n",
    "print(\"Anki 패키지 생성 완료!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두번째 OCR 문제 질문해보기\n",
    "1. 해당 사진을 찍은뒤 구글포토에서 구글렌즈로 이미지검색을 하면 상당히 정확한 결과로 한글이 인식되는것을 확인, \n",
    "2. 먼저 로컬 png파일로 확인\n",
    "\n",
    "## openai 답변\n",
    "이미지에서 텍스트를 추출하고 이를 파이썬에서 텍스트 파일로 작성하는 코드 제공\n",
    "실행하려면 'google-cloud-vision' 라이브러리가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아 맞다 라이브러리\n",
    "%pip install --upgrade google-api-python-client\n",
    "%pip install --upgrade google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "import io\n",
    "\n",
    "# 이미지 파일 경로 설정\n",
    "image_file_path = \"이미지 파일 경로를 여기에 입력하세요\"\n",
    "\n",
    "# Vision API 클라이언트 초기화\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# 이미지 파일에서 텍스트 읽기\n",
    "with io.open(image_file_path, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "image = vision.Image(content=content)\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "\n",
    "# 텍스트 추출 결과를 텍스트 파일에 작성\n",
    "output_file_path = \"출력할 텍스트 파일 경로를 여기에 입력하세요\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for text in texts:\n",
    "        output_file.write(text.description + \"\\n\")\n",
    "print(\"텍스트를 파일에 작성하였습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 두번째 OCR 문제 질문해보기2\n",
    "3. 구글포토에서 가지고와서 분석후 텍스트 저장\n",
    "## openai답변 \n",
    "구글 포토 API를 사용하여 앨범에서 사진을 가져오는 파이썬 예제를 제공하겠습니다. Google Photos API를 사용하기 전에 Google Cloud Console에서 프로젝트를 생성하고, Google Photos Library API를 활성화하며, OAuth 2.0 클라이언트 ID를 생성해야 합니다. 이 예제는 이러한 설정이 이미 완료되었다고 가정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'YOUR_CLIENT_SECRET_FILE.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m scopes \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://www.googleapis.com/auth/photoslibrary.readonly\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# 사용자 인증 흐름 설정\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m flow \u001B[38;5;241m=\u001B[39m \u001B[43mInstalledAppFlow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_client_secrets_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_secrets_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscopes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscopes\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# 사용자 인증 및 액세스 토큰 획득\u001B[39;00m\n\u001B[1;32m     19\u001B[0m credentials \u001B[38;5;241m=\u001B[39m flow\u001B[38;5;241m.\u001B[39mrun_console()\n",
      "File \u001B[0;32m/Volumes/disk/aiapi/pythonProject/.venv/lib/python3.12/site-packages/google_auth_oauthlib/flow.py:198\u001B[0m, in \u001B[0;36mFlow.from_client_secrets_file\u001B[0;34m(cls, client_secrets_file, scopes, **kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_client_secrets_file\u001B[39m(\u001B[38;5;28mcls\u001B[39m, client_secrets_file, scopes, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    185\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a :class:`Flow` instance from a Google client secrets file.\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \n\u001B[1;32m    187\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;124;03m        Flow: The constructed Flow instance.\u001B[39;00m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 198\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclient_secrets_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m json_file:\n\u001B[1;32m    199\u001B[0m         client_config \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(json_file)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_client_config(client_config, scopes\u001B[38;5;241m=\u001B[39mscopes, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'YOUR_CLIENT_SECRET_FILE.json'"
     ]
    }
   ],
   "source": [
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import os\n",
    "\n",
    "# OAuth 2.0 클라이언트 ID와 비밀 정보 설정\n",
    "client_secrets_file = 'YOUR_CLIENT_SECRET_FILE.json'\n",
    "\n",
    "# 스코프 설정\n",
    "# https://www.googleapis.com/auth/photoslibrary.readonly 스코프를 사용하여 읽기 전용 액세스 권한을 요청합니다.\n",
    "scopes = ['https://www.googleapis.com/auth/photoslibrary.readonly']\n",
    "\n",
    "# 사용자 인증 흐름 설정\n",
    "flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    client_secrets_file,\n",
    "    scopes=scopes\n",
    ")\n",
    "\n",
    "# 사용자 인증 및 액세스 토큰 획득\n",
    "credentials = flow.run_console()\n",
    "\n",
    "# Google Photos API 서비스 객체 생성\n",
    "service = build('photoslibrary', 'v1', credentials=credentials)\n",
    "\n",
    "# 앨범 목록 가져오기\n",
    "results = service.albums().list(\n",
    "    pageSize=10, # 한 페이지에 표시할 앨범 수\n",
    "    excludeNonAppCreatedData=False # 앱 외부에서 생성된 데이터 포함 여부\n",
    ").execute()\n",
    "\n",
    "albums = results.get('albums', [])\n",
    "\n",
    "if not albums:\n",
    "    print('앨범을 찾을 수 없습니다.')\n",
    "else:\n",
    "    print('앨범 목록:')\n",
    "    for album in albums:\n",
    "        print(f\"{album['title']} (ID: {album['id']})\")\n",
    "\n",
    "# 특정 앨범에서 사진 가져오기 (첫 번째 앨범의 ID 사용)\n",
    "if albums:\n",
    "    album_id = albums[0]['id'] # 첫 번째 앨범의 ID\n",
    "    response = service.mediaItems().search(body={'albumId': album_id}).execute()\n",
    "    items = response.get('mediaItems', [])\n",
    "    if not items:\n",
    "        print('사진을 찾을 수 없습니다.')\n",
    "    else:\n",
    "        for item in items:\n",
    "            print(f\"사진 제목: {item['filename']}, URL: {item['baseUrl']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cㅊㅊㅊcㅊㅊㅊcㅊㅊㅊcㅊㅊㅊcㅊㅊㅊcㅊㅊㅊ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "구글 포토에서 추가된 과거 시험 사진을 텍스트로 변환하여 저장하고, 위에서 제시한 questions_with_choices 형식으로 작성하기 위한 자동화 프로세스를 만들고자 한다면, 여러 단계를 거쳐야 합니다. 이 과정에는 이미지에서 텍스트를 추출하는 OCR (Optical Character Recognition) 과정, 추출된 텍스트의 정제 및 포맷팅, 그리고 최종적으로 원하는 데이터 구조로의 변환 작업이 포함됩니다.\n",
    "\n",
    "## 1단계: 구글 포토에서 사진 가져오기\n",
    "구글 포토 API를 사용하여 과거 시험 사진들에 접근합니다.\n",
    "구글 클라우드 플랫폼(GCP)에서 프로젝트를 생성하고, 구글 포토 API를 활성화합니다.\n",
    "OAuth 2.0을 통해 인증하고, 필요한 권한을 얻어 사진에 접근합니다.\n",
    "\n",
    "## 2단계: OCR을 이용한 텍스트 추출\n",
    "추출된 사진들을 Google Cloud Vision API 같은 OCR 서비스에 전송하여 이미지 내의 텍스트를 추출합니다.\n",
    "Google Cloud Vision API를 사용하기 위해서는 GCP에서 해당 서비스를 활성화하고, API 키를 생성해야 합니다.\n",
    "\n",
    "## 3단계: 추출된 텍스트의 정제 및 포맷팅\n",
    "OCR로부터 얻은 텍스트는 종종 잡음이 포함되어 있기 때문에, 정규 표현식(regular expressions)을 사용하여 필요한 정보만을 추출하고, 잡음을 제거합니다.\n",
    "문제 번호, 문제 내용, 선택지 등을 구분할 수 있는 패턴을 식별하고, 이를 기반으로 데이터를 구조화합니다.\n",
    "\n",
    "## 4단계: 데이터 구조로 변환\n",
    "정제된 텍스트 데이터를 Python의 리스트와 딕셔너리 같은 데이터 구조로 변환합니다. 각 문제와 선택지를 questions_with_choices 형식에 맞게 배열에 추가합니다.\n",
    "자동화 스크립트 예시 (가상의 코드)\n",
    "\n",
    "\n",
    "# 메인 프로세스\n",
    "photos = fetch_photos()\n",
    "raw_text = extract_text_from_photos(photos)\n",
    "questions = format_questions(raw_text)\n",
    "\n",
    "print(questions)\n",
    "주의 사항\n",
    "실제 구현을 위해서는 Google Cloud Platform, Google Photos API, Google Cloud Vision API에 대한 상세한 문서를 참조하고, 필요한 권한과 API 키를 정확히 설정해야 합니다.\n",
    "OCR 결과의 정확성은 사진의 품질, 글자의 명확성에 크게 의존하므로, 가능한 한 고해상도의 사진을 사용하고, 글자가 선명하게 보이도록 합니다.\n",
    "위의 설명은 고수준에서의 개요를 제공하는 것이며, 각 단계에는 구체적인 구현이 필요합니다. 개발 과정에서 API 문서와 공식 가이드를 참조하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google_photos_api\n",
    "import google_vision_api\n",
    "import re\n",
    "\n",
    "def fetch_photos():\n",
    "    # Google Photos API를 사용해 사진을 가져오는 코드\n",
    "    pass\n",
    "\n",
    "def extract_text_from_photos(photos):\n",
    "    # Google Cloud Vision API를 사용해 사진에서 텍스트를 추출하는 코드\n",
    "    pass\n",
    "\n",
    "def format_questions(raw_text):\n",
    "    # 추출된 텍스트를 정제하고, questions_with_choices 형식으로 변환하는 코드\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "특히 Google 포토 및 Google 렌즈와 같은 제품 내에서 Google의 이미지 OCR(광학 문자 인식) 기술은 인공 지능(AI) 기술의 정교한 혼합에 의존합니다. Google은 독점 기술의 복잡한 세부정보를 항상 공개하지는 않지만 이용 가능한 정보 및 업계 표준을 기반으로 Google의 OCR 시스템이 다음 AI 기술을 활용하고 있음을 추론할 수 있습니다.\n",
    "\n",
    "CNN(컨볼루셔널 신경망): Google 이미지 OCR의 중심에는 특히 이미지 인식 작업에 적합한 CNN이 있습니다. CNN은 사람의 감독 없이 중요한 특징을 자동으로 감지할 수 있으므로 이미지의 패턴, 모양 및 문자를 인식하는 데 이상적입니다.\n",
    "\n",
    "\n",
    "RNN(반복 신경망) 및 LSTM(장단기 기억) 네트워크: CNN을 통한 초기 문자 인식 후 RNN, 특히 LSTM은 문자 시퀀스를 처리하는 데 종종 사용됩니다. 이러한 모델은 텍스트 시퀀스 내의 컨텍스트와 종속성을 이해하는 데 능숙하므로 이미지의 텍스트를 정확하게 해석하고 기록하는 데 필수적입니다.\n",
    "\n",
    "\n",
    "주의 메커니즘: OCR 기술의 최근 발전에는 주의 메커니즘이 통합되어 모델이 텍스트를 디코딩하는 동안 이미지의 특정 부분에 집중할 수 있습니다. 이는 열과 같이 텍스트가 비선형 형식으로 정렬되거나 이미지에 텍스트와 텍스트가 아닌 요소가 혼합되어 있는 복잡한 문서를 처리하는 데 특히 유용합니다.\n",
    "\n",
    "\n",
    "전이 학습: Google은 전이 학습을 활용하여 OCR 모델의 효율성과 정확성을 향상합니다. 방대한 데이터 세트에 대해 모델을 사전 훈련한 다음 특정 OCR 작업에 맞게 미세 조정함으로써 Google은 조명이 낮거나 이미지 품질이 좋지 않은 까다로운 조건에서도 높은 수준의 정확도를 달성할 수 있습니다.\n",
    "\n",
    "\n",
    "데이터 증강: 모델을 더욱 강력하게 만들기 위해 Google은 데이터 증강 기술을 사용하여 훈련 데이터세트를 인위적으로 확장할 가능성이 높습니다. 여기에는 크기 조정, 자르기, 회전 또는 노이즈 추가와 같은 이미지 수정이 포함될 수 있으며, 이는 입력 데이터가 훈련 데이터와 크게 다른 경우에도 모델이 잘 작동하는 데 도움이 됩니다.\n",
    "\n",
    "\n",
    "앙상블 방법: 기계 학습에서는 정확도를 높이기 위해 여러 모델의 예측을 결합하는 것이 일반적입니다. Google의 OCR은 문자 인식의 전반적인 성능과 신뢰성을 향상시키기 위해 각각 약간 다른 매개변수나 데이터로 훈련된 모델의 앙상블을 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "언어 모델: 단순히 문자를 인식하는 것 이상으로 텍스트를 이해하려면 사용되는 언어를 이해해야 하는 경우가 많습니다. Google의 OCR 시스템은 오류를 수정하고 문법과 문맥을 기반으로 텍스트를 이해하기 위해 언어 모델을 통합할 가능성이 높습니다. 이는 복잡한 규칙이 있는 언어나 속어, 약어 및 기타 비표준 언어 사용을 다룰 때 특히 중요합니다.\n",
    "\n",
    "\n",
    "Google은 성능 개선을 위해 최신 AI 연구와 방법론을 통합하여 OCR 기술을 지속적으로 개선하고 있습니다. 이러한 지속적인 혁신을 통해 OCR은 현재 기술로 가능한 것의 최전선에 머물 수 있습니다.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
